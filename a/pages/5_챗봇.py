import streamlit as st
from langchain.schema import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.vectorstores.utils import DistanceStrategy
from langchain.llms import Ollama
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA
import pandas as pd
import random
import os
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(layout="wide")
st.header("ğŸ¤– ë‹¹ë‡¨ ìš´ë™ ì¶”ì²œ ì±—ë´‡ 'EASYë‹¹'")
with st.expander(":page_facing_up:  **ì±—ë´‡ ì‚¬ìš© ì„¤ëª…ì„œ**",expanded=False):
        st.write("""  
                    -  ë‹¹ë‡¨ í™˜ìë¥¼ ìœ„í•œ ìš´ë™ ë©”ë‰´ì–¼ì— ëŒ€í•´ ì§ˆë¬¸ í• ì‹œ í¬ë¡¤ë§ ë°ì´í„°ì—ì„œ RAGì‹œìŠ¤í…œì´ ì°¾ì•„ì™€ ë‹µë³€ì„ í•©ë‹ˆë‹¤.  ì¶œì²˜:http://www.metrohosp.com/sub05/healthguide_contents.php?idx=3020&sub=1\n
                    -  ë‹¹ë‡¨ í™•ë¥ ì´ 50% ì´ìƒì¸ ì‚¬ìš©ìê°€ 'ìš´ë™ ì¢…ë¥˜ ì¶”ì²œ'ì´ë¼ëŠ” ê¸€ìê°€ ë“¤ì–´ê°€ê²Œ ì§ˆë¬¸ í•  ì‹œ ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ ìš´ë™ ì¢…ë¥˜ì™€ ë™ì˜ìƒ ë§í¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤. (ë‹¹ë‡¨ í™•ë¥ ì´ 50% ì´í•˜ì¸ ì‚¬ìš©ìëŠ” ì¼ë°˜ LLMì´ ì¶”ì²œ) ì¶œì²˜:https://nfa.kspo.or.kr/classroom/program/selectPrescriptionMovieList.kspo\n
                    -  ê·¸ ì™¸ì˜ ì§ˆë¬¸ì„ í•  ì‹œ ê¸°ë³¸ LLMì´ ë‹µë³€ì„ í•©ë‹ˆë‹¤. 
                 """)


# ì„¸ì…˜ì— ì €ì¥ëœ ê°’ ë¶ˆëŸ¬ì˜¤ê¸°
data = st.session_state.data_with_percent
# í”¼ì²˜ ìˆœì„œ ë³€ê²½
feature_order = ['age', 'sex','HE_chol', 'HE_wc', 'HE_crea', 'HE_alt', 'HE_TG', 'HE_Upro', 'percent']

# í”¼ì²˜ ìˆœì„œ ì •ë ¬
data = data[feature_order]
with st.expander(":pill: ì‚¬ìš©ìì˜ ë‹¹ë‡¨ ì˜ˆì¸¡ ê²°ê³¼",expanded=False):
        st.write(data)


# ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
def initialize_embedding_model():
    try:
        return HuggingFaceEmbeddings(
            model_name='jhgan/ko-sroberta-nli',
            model_kwargs={'device': 'cuda'},
            encode_kwargs={'normalize_embeddings': True},
        )
    except Exception as e:
        st.error(f"ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

embeddings_model = initialize_embedding_model()


with open('C:/Users/SAMSUNG/[ì€ë¹„]/[ê³µê³µë°ì´í„° ë¶„ì„ë° AIì±—ë´‡ ê³¼ì •]/íŒ€í”„ë¡œì íŠ¸ 3ì°¨ ëŒ€ì‹œë³´ë“œ/ëŒ€ì‹œë³´ë“œ/pages/__func__/crawled_data.txt', 'r', encoding='utf-8') as f:
    content = f.read()

# í…ìŠ¤íŠ¸ ë¶„í•  ë° ì„ë² ë”©
def split_and_embed_text(content, embeddings_model):
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    chunks = text_splitter.split_text(content)
    documents = [Document(page_content=chunk) for chunk in chunks]
    return FAISS.from_documents(
        documents,
        embedding=embeddings_model,
        distance_strategy=DistanceStrategy.COSINE
    )

vectorstore = split_and_embed_text(content, embeddings_model)

# LLM ëª¨ë¸ ì´ˆê¸°í™”
llm = Ollama(model="gemma2")

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
prompt_template = """
### [INST]
ì§€ì¹¨: ë‹¹ì‹ ì˜ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— í•œê¸€ë¡œ ë‹µí•˜ì‹­ì‹œì˜¤. 
ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ë§¥ë½ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

{context}

### QUESTION:
{question}

[/INST]
"""

prompt = PromptTemplate(
    input_variables=["context", "question"],
    template=prompt_template,
)

# ìš´ë™ ë°ì´í„° ë¡œë“œ
file_path = 'C:/Users/SAMSUNG/[ì€ë¹„]/[ê³µê³µë°ì´í„° ë¶„ì„ë° AIì±—ë´‡ ê³¼ì •]/íŒ€í”„ë¡œì íŠ¸ 3ì°¨ ëŒ€ì‹œë³´ë“œ/ëŒ€ì‹œë³´ë“œ/pages/__func__/exercise.csv'
exercise_data = pd.read_csv(file_path)

# ë‚˜ì´ì— ë”°ë¥¸ ëª©í‘œ ê·¸ë£¹ ë§¤í•‘
def map_target(user_age):
    if 11 <= user_age <= 12:
        return 'ìœ ì†Œë…„'
    elif 13 <= user_age <= 18:
        return 'ì²­ì†Œë…„'
    elif 19 <= user_age <= 64:
        return 'ì„±ì¸'
    elif user_age >= 65:
        return 'ì–´ë¥´ì‹ '
    else:
        return 'ì•Œ ìˆ˜ ì—†ìŒ'

# ìš´ë™ ì¶”ì²œ í•¨ìˆ˜
def recommend_exercise(user_age):
    # ì‚¬ìš©ì ë‚˜ì´ì— ë”°ë¥¸ ëª©í‘œ ê·¸ë£¹ ì„¤ì • (ì´ í•¨ìˆ˜ëŠ” ì´ë¯¸ ì •ì˜ë˜ì–´ ìˆë‹¤ê³  ê°€ì •)
    target_group = map_target(user_age)

    # ì¶”ì²œí•  ìš´ë™ ê²€ìƒ‰
    filtered_exercises = []
    for _, row in exercise_data.iterrows():
        # rowì—ì„œ í•„ìš”í•œ ê°’ ê°€ì ¸ì˜¤ê¸°
        exercise_name = row['Exercise_name']
        fitness_category = row['Fitness_category']
        target = row['Target']
        video_url = row['Video_URL']

        # ì‚¬ìš©ì ëª©í‘œ ê·¸ë£¹ê³¼ ì¼ì¹˜í•˜ëŠ” ìš´ë™ ì¶”ê°€
        if target == target_group:
            filtered_exercises.append({
                'exercise_name': exercise_name,
                'fitness_category': fitness_category,
                'video_url': video_url
            })

    # ì¹´í…Œê³ ë¦¬ë³„ ëœë¤ ì¶”ì²œ
    category_dict = {}
    for exercise in filtered_exercises:
        category = exercise['fitness_category']
        if category not in category_dict:
            category_dict[category] = []
        category_dict[category].append(exercise)

    # ì¹´í…Œê³ ë¦¬ë³„ ëœë¤ìœ¼ë¡œ ìš´ë™ ì„ íƒ
    recommendations = []
    for category, exercises in category_dict.items():
        if exercises:  # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì— ìš´ë™ì´ ìˆëŠ” ê²½ìš°
            recommendations.append(random.choice(exercises))

    # ì¶”ì²œ ê²°ê³¼ ë°˜í™˜
    if recommendations:
        result = f"{target_group}ì„ ìœ„í•œ ì¶”ì²œ ìš´ë™:\n"
        for rec in recommendations:
            result += f"ìš´ë™ëª…: {rec['exercise_name']}, ì¹´í…Œê³ ë¦¬: {rec['fitness_category']}, ë¹„ë””ì˜¤ ë§í¬: {rec['video_url']}\n"
        return result
    else:
        return "ì¶”ì²œí•  ìš´ë™ì´ ì—†ìŠµë‹ˆë‹¤."


# vectorstoreë¥¼ ì‚¬ìš©í•˜ë„ë¡ ë³€ê²½
qa = RetrievalQA.from_chain_type(llm=llm,
                                 chain_type='stuff',
                                 retriever=vectorstore.as_retriever(
                                     search_type='mmr',
                                     search_kwargs={'k': 3, 'fetch_k': 10}),
                                 return_source_documents=True)


# ì¿¼ë¦¬ ì²˜ë¦¬ í•¨ìˆ˜ 

def process_query(user_query, user_age, percent):
    # "ìš´ë™ ì¢…ë¥˜ ì¶”ì²œ"ì´ í¬í•¨ëœ ê²½ìš°
    if "ìš´ë™ ì¢…ë¥˜ ì¶”ì²œ" in user_query:
        if percent >= 50:
            exercise_recommendations = recommend_exercise(user_age)
            response = prompt | llm
            result = response.invoke({
                "context": """ë‹¹ë‡¨ì¸ì—ê²Œ ì í•©í•œ ìš´ë™ì„ ì¶”ì²œí•´ì£¼ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
                    ì´ ì‹œìŠ¤í…œì€ ë‹¹ë‡¨ì¸ì˜ ë‚˜ì´ì— ë”°ë¼ ìš´ë™ì¢…ë¥˜, ì¹´í…Œê³ ë¦¬, ë¹„ë””ì˜¤ ë§í¬ë¥¼ í•„ìˆ˜ì ìœ¼ë¡œ ì œê³µí•©ë‹ˆë‹¤.
                    ë‹¹ë‡¨ì¸ì˜ ìš´ë™ì‹œ ì£¼ì˜ì‚¬í•­ì„ ê°„ëµí•˜ê²Œ ì œê³µí•©ë‹ˆë‹¤.""",
                "question": exercise_recommendations
            })
            return f"*ë‹¹ì‹ ì˜ ë‹¹ë‡¨ ìœ„í—˜ë„ëŠ” ({percent:.2f}%)ì…ë‹ˆë‹¤. ì¶”ì²œ ìš´ë™ì„ ì œê³µí•©ë‹ˆë‹¤.* \n{result}"
        else:
            response = prompt | llm
            result = response.invoke({
                "context": "í•œê¸€ë¡œ ë‹µë³€í•˜ì„¸ìš”. ë‹¹ë‡¨ ìœ„í—˜ì´ ë‚®ì€ ì‚¬ìš©ìì…ë‹ˆë‹¤.",
                "question": user_query
            })
            return f"*ë‹¹ì‹ ì˜ ë‹¹ë‡¨ ìœ„í—˜ì€ ë‚®ìŠµë‹ˆë‹¤ ({percent:.2f}%). ì¼ë°˜ì ì¸ ê±´ê°• ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤.* \n{result}"
    # ë²¡í„°ìŠ¤í† ì–´ì— ì €ì¥ëœ ë°ì´í„°ì—ì„œ ì°¾ì•„ì„œ ë‹µë³€
    result = qa({
        "query": user_query,
        "context": "í•œê¸€ë¡œ ë‹µë³€í•˜ì„¸ìš”."})
    negative_keywords = [
    "cannot give", "can't give", "no information", "not available", "cannot answer",
    "unable to provide", "not possible", "insufficient data", "lack of information","can't recommend","cannot recommend"
]

    if result['result']:
      if any(keyword in result['result'].lower() for keyword in negative_keywords):
          # LLMì„ í˜¸ì¶œí•˜ì—¬ ìƒˆë¡œìš´ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜´
          response = prompt | llm
          result = response.invoke({
              "context": "í•œê¸€ë¡œ ì„±ì˜ê» ë‹µë³€í•˜ì„¸ìš”.",
              "question": user_query  # queryë¥¼ questionìœ¼ë¡œ ì „ë‹¬
          })
          return f"LLMì´ ì§ˆë¬¸ì— ëŒ€í•´ ë‹µë³€í•©ë‹ˆë‹¤. \n{result}"
      return f"RAG ì‹œìŠ¤í…œì´ ì§ˆë¬¸ì— ëŒ€í•´ ë‹µë³€í•©ë‹ˆë‹¤. {result['result']} \nì¶œì²˜: {result['source_documents']}"



# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'generated' not in st.session_state:
    st.session_state['generated'] = []
if 'past' not in st.session_state:
    st.session_state['past'] = []

# ì‚¬ìš©ì ì…ë ¥ í¼
with st.form('form', clear_on_submit=True):
    user_input = st.text_input('ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”: ', '', key='input')
    submitted = st.form_submit_button('ë¬¼ì–´ë³´ê¸°')


user_age = int(data['age'][0])
percent = float(data['percent'][0])  # percent ê°’ ì¶”ì¶œ

if submitted and user_input:
    with st.spinner("ì±—ë´‡ì´ ë‹µë³€ ìƒê° ì¤‘..."):
        try:
            output = process_query(user_input, user_age, percent)  # percent ì „ë‹¬
            st.session_state.past.append(user_input)
            st.session_state.generated.append(output)
        except Exception as e:
            st.error(f"ì¿¼ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


# ì´ì „ ëŒ€í™” ì¶œë ¥
if st.session_state['generated']:
    for i in range(len(st.session_state['generated']) - 1, -1, -1):
        st.write(f"**ì‚¬ìš©ì**: {st.session_state['past'][i]}")
        st.write(f"**EASYë‹¹**: {st.session_state['generated'][i]}")
        st.header(" ")
